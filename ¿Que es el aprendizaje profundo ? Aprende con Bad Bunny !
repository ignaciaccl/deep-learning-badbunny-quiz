ğŸ§  Â¿QuÃ© es el aprendizaje profundo?
El aprendizaje profundo es una forma avanzada de aprendizaje automÃ¡tico. Usa redes neuronales artificiales que funcionan como el cerebro humano: aprenden a partir de datos.
ğŸ§ ğŸ’» En vez de neuronas biolÃ³gicas, usamos funciones matemÃ¡ticas que "activan" seÃ±ales.

ğŸ¤ Ejemplo con Bad Bunny
SupÃ³n que tenemos una red neuronal que escucha una frase y dice de quÃ© canciÃ³n es.
 Por ejemplo, le das esta lÃ­nea:
â€œBaby, la vida es un ciclo, y lo que no sirve yo no lo recicloâ€
Y el modelo te dice:
ğŸ¶ Esa frase es de â€œYonaguniâ€ âœ…

ğŸ”¢ Â¿CÃ³mo aprende esto la red neuronal?
Entrenamos al modelo con muchas letras de canciones de Bad Bunny:


Cada lÃ­nea de letra es una entrada (x).


La canciÃ³n a la que pertenece es la etiqueta (y).


Por ejemplo:

 vbnet
CopiarEditar
x: "Baby, la vida es un ciclo..."
y: "Yonaguni"


La red neuronal pasa esa frase por muchas capas de â€œneuronasâ€ (funciones matemÃ¡ticas) que procesan:


Palabras


Estructura


Ritmo


Estilo (por ejemplo, frases como â€œbebÃ©â€ o â€œya tÃº sabesâ€ aparecen en ciertas canciones)


La red genera una probabilidad de que esa frase sea de cada canciÃ³n:

 vbnet
CopiarEditar
Yonaguni: 90%
Safaera: 5%
TitÃ­ Me PreguntÃ³: 5%


Como Yonaguni tiene el porcentaje mÃ¡s alto, esa es la predicciÃ³n final ğŸ¯



ğŸ” Â¿Y cÃ³mo mejora la red?
ğŸ‘‰ Al principio se equivoca, como cuando tÃº escuchas un Ã¡lbum nuevo y no sabes cuÃ¡l es cuÃ¡l.
Pero poco a poco va â€œaprendiendoâ€:
Calcula su error (por ejemplo, dijo "Safaera" pero era "Yonaguni").


Ajusta los pesos (w) de la red para que la prÃ³xima vez lo haga mejor.


Repite esto miles de veces con muchÃ­simas frases (como si escuchara TODO el disco mil veces).


Eso se llama entrenamiento con descenso de gradiente ğŸª‚, una tÃ©cnica que baja el error poco a poco.







ğŸ§ Â¿Y para quÃ© sirve esto?
Redes neuronales como esta se usan en:
Reconocimiento de voz (como Siri entendiendo â€œpon mÃºsica de Bad Bunnyâ€)


ClasificaciÃ³n de texto (saber si una letra es triste, feliz, etc.)


Recomendaciones musicales (cuando Spotify te recomienda â€œsi te gusta TitÃ­ Me PreguntÃ³, prueba â€˜Me Porto Bonitoâ€™â€).



ğŸ“Œ Resumen estilo Bad Bunny
Concepto
Ejemplo con Bad Bunny
Entrada (x)
Letra de una canciÃ³n
Salida (y)
El nombre de la canciÃ³n
Red neuronal
Cerebro que escucha letras y predice canciones
Pesos (w)
â€œExperienciaâ€ de la red: cuÃ¡nto pesan ciertas palabras o frases
FunciÃ³n de activaciÃ³n
Decide si una seÃ±al debe pasar (como si una frase suena muy al estilo de Bad Bunny)
FunciÃ³n de pÃ©rdida
QuÃ© tan mal predijo la red (ej: dijo "Safaera" pero era "Yonaguni")
Entrenamiento
Proceso de escuchar miles de frases para mejorar las predicciones

















ğŸ§  QUIZ DE APRENDIZAJE PROFUNDO (VERSIÃ“N BAD BUNNY)
1. Bad Bunny quiere que su IA recomiende canciones tristes. Â¿QuÃ© debe hacer primero?
A. Darle las canciones favoritas de sus fans
 B. EnseÃ±arle letras tristes y alegres con etiquetas
 C. Poner todas sus canciones en orden alfabÃ©tico
 D. Hacer que escuche el Ã¡lbum completo sin decirle nada

2. Cuando una red neuronal ajusta sus pesos para mejorar, eso se llama:
A. Cambiar el beat
 B. Backpropagation
 C. Afinar el autotune
 D. Reggaetune learning

3. Si la red neuronal confunde "TitÃ­ me preguntÃ³" con "Me porto bonito", Â¿quÃ© estÃ¡ pasando?
A. No sabe espaÃ±ol
 B. Tiene overfitting
 C. EstÃ¡ generalizando mal porque ambas tienen temas similares
 D. Se enamorÃ³ de TitÃ­

4. Â¿CuÃ¡l es el propÃ³sito de la funciÃ³n de activaciÃ³n en una red neuronal?
A. Elegir el mejor reggaetÃ³n de la semana
 B. Aumentar el volumen de la salida
 C. Decidir si una neurona transmite informaciÃ³n o no
 D. Mostrar si la canciÃ³n es explÃ­cita

5. Si entrenas una red con miles de letras de Bad Bunny para que adivine la canciÃ³n, estÃ¡s haciendo:
A. Machine twerking
 B. Deep learning supervisado
 C. Auto-reggaetÃ³n no supervisado
 D. Aprendizaje sin perreo

6. Bad Bunny quiere que su IA identifique si una letra es de amor o de fiesta. Â¿QuÃ© tipo de salida deberÃ­a tener su modelo?
A. Texto plano
 B. Una probabilidad por cada categorÃ­a
 C. Un beat nuevo
 D. El nombre de un Ã¡lbum

7. En deep learning, Â¿quÃ© significa â€œÃ©pocaâ€ (epoch)?
A. El nÃºmero de giras de Bad Bunny
 B. Una capa especial de reggaetÃ³n lento
 C. Una vuelta completa por todos los datos de entrenamiento
 D. El nÃºmero de fans que lloraron con "Amorfoda"

8. Â¿QuÃ© problema ocurre si la red memoriza todas las letras pero falla con frases nuevas?
A. Overfitting
 B. Underperreo
 C. Buen flow
 D. Reinicio de tour

9. Â¿QuÃ© es el descenso de gradiente?
A. Cuando la canciÃ³n baja el beat
 B. Una tÃ©cnica para reducir el error ajustando pesos poco a poco
 C. El nombre de su nuevo Ã¡lbum
 D. Cuando baja la energÃ­a del concierto

10. Â¿CuÃ¡l de estas opciones NO es parte de una red neuronal profunda?
A. Capa de entrada
 B. Capa oculta
 C. Capa de salida
 D. Capa de fiesta


